{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb31654c-7750-46a0-aea8-b81a726af297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gym\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "from gym import Env, spaces\n",
    "from stable_baselines3 import PPO\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cabd525-7833-48a1-b299-932d4dac421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diets = pd.read_csv(r'C:\\Users\\himan\\OneDrive\\Desktop\\Database ML\\diets.csv')\n",
    "medications = pd.read_csv(r'C:\\Users\\himan\\OneDrive\\Desktop\\Database ML\\medications.csv')\n",
    "precautions = pd.read_csv(r'C:\\Users\\himan\\OneDrive\\Desktop\\Database ML\\precautions_df.csv')\n",
    "symptom_severity = pd.read_csv(r'C:\\Users\\himan\\OneDrive\\Desktop\\Database ML\\Symptom-severity.csv')\n",
    "symptoms = pd.read_csv(r'C:\\Users\\himan\\OneDrive\\Desktop\\Database ML\\symtoms_df.csv')\n",
    "workouts = pd.read_csv(r'C:\\Users\\himan\\OneDrive\\Desktop\\Database ML\\workout_df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1778da5-f82b-4444-8c38-c4ebcf78d576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare symptoms data\n",
    "symptoms_long = symptoms.melt(id_vars=['Disease'], value_vars=[f'Symptom_{i}' for i in range(1, 5)], var_name='SymptomType', value_name='Symptom')\n",
    "symptoms_severity = pd.merge(symptoms_long, symptom_severity, on='Symptom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61859489-6130-4a0a-b54e-01415668a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming you have a dataframe symptoms_severity with a column 'Symptom'\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')  # Updated parameter name\n",
    "encoded_symptoms = encoder.fit_transform(symptoms_severity[['Symptom']])\n",
    "encoded_symptoms_df = pd.DataFrame(encoded_symptoms, columns=encoder.get_feature_names_out(['Symptom']))\n",
    "symptoms_severity_encoded = pd.concat([symptoms_severity.drop(['Symptom'], axis=1), encoded_symptoms_df], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c70a00a-eb70-4351-af49-76aa89885f66",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 16 (4242955986.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[39], line 18\u001b[1;36m\u001b[0m\n\u001b[1;33m    self.state = symptoms_severity_encoded.sample(1).iloc[0].values\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after function definition on line 16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class HealthcareEnv(Env):\n",
    "    def __init__(self):\n",
    "        super(HealthcareEnv, self).__init__()\n",
    "        self.n_actions = len(diets) + len(medications) + len(workouts)  # Define number of actions\n",
    "        self.n_features = len(symptoms_severity_encoded.columns)  # Number of features\n",
    "\n",
    "        # Define action and observation space\n",
    "        self.action_space = spaces.Discrete(self.n_actions)\n",
    "        # Ensure the observation space shape is correct: should match the shape of the state\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(self.n_features,), dtype=np.float32)\n",
    "\n",
    "        # Initialize state\n",
    "        self.state = None\n",
    "        self.done = False\n",
    "\n",
    "    def reset(self):\n",
    "    # Sample a random initial state from the encoded data\n",
    "    self.state = symptoms_severity_encoded.sample(1).iloc[0].values\n",
    "    print(f\"Sampled state: {self.state}\")  # Check sampled state\n",
    "    print(f\"State shape: {self.state.shape}\")  # Check shape of the sampled state\n",
    "\n",
    "    # Ensure that the sampled state is numeric\n",
    "    if isinstance(self.state[0], str):\n",
    "        raise ValueError(\"State contains non-numeric values, check the encoding.\")\n",
    "\n",
    "    self.done = False\n",
    "    return np.array(self.state, dtype=np.float32)\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "    # Update self.state based on the action (placeholder logic)\n",
    "    # Here you could modify self.state to represent the effect of the action.\n",
    "    # For demonstration, let's just simulate a change:\n",
    "    \n",
    "    # Assume action impacts the state; replace this logic as needed\n",
    "    self.state[-1] = max(0, self.state[-1] - 0.1)  # Decrease severity for simplicity\n",
    "\n",
    "    reward = -self.state[-1]  # Assuming 'Severity' is the last column\n",
    "    self.done = False  # Adjust this as necessary\n",
    "\n",
    "    # Return the updated state, reward, and done flag\n",
    "    return np.array(self.state, dtype=np.float32), reward, self.done, {}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e11fe89c-eae5-4585-9a49-054decd0335c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize environment\n",
    "env = HealthcareEnv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d53690c8-4bb2-4bb5-99e1-7218a400cde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\himan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the RL model\n",
    "model = PPO('MlpPolicy', env, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47438d10-345b-4e8d-87ef-5fa99bdf4c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight                         int64\n",
      "Disease_Chicken pox             bool\n",
      "Disease_Chronic cholestasis     bool\n",
      "Disease_Drug Reaction           bool\n",
      "Disease_Fungal infection        bool\n",
      "Disease_Hepatitis B             bool\n",
      "Disease_Jaundice                bool\n",
      "SymptomType_Symptom_1           bool\n",
      "Symptom_itching                 bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(symptoms_severity_encoded.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a1dd2a6-4c79-43ec-a93d-2b3329176351",
   "metadata": {},
   "outputs": [],
   "source": [
    "symptoms_severity_encoded = pd.get_dummies(symptoms_severity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7409de3f-f4bf-462f-881f-98cef7e91e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight                         int64\n",
      "Disease_Chicken pox             bool\n",
      "Disease_Chronic cholestasis     bool\n",
      "Disease_Drug Reaction           bool\n",
      "Disease_Fungal infection        bool\n",
      "Disease_Hepatitis B             bool\n",
      "Disease_Jaundice                bool\n",
      "SymptomType_Symptom_1           bool\n",
      "Symptom_itching                 bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(symptoms_severity_encoded.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef4d0d2e-abc7-48ba-ac84-1bc7bb8c7a5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (9,) into shape (3,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Test the model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m state \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:287\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfOnPolicyAlgorithm,\n\u001b[0;32m    278\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    283\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    284\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfOnPolicyAlgorithm:\n\u001b[0;32m    285\u001b[0m     iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 287\u001b[0m     total_timesteps, callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_learn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    295\u001b[0m     callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\base_class.py:423\u001b[0m, in \u001b[0;36mBaseAlgorithm._setup_learn\u001b[1;34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset_num_timesteps \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    424\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_episode_starts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mnum_envs,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;66;03m# Retrieve unnormalized observation for saving into the buffer\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:78\u001b[0m, in \u001b[0;36mDummyVecEnv.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     76\u001b[0m     maybe_options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptions\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options[env_idx]} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options[env_idx] \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m     77\u001b[0m     obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs[env_idx]\u001b[38;5;241m.\u001b[39mreset(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds[env_idx], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmaybe_options)\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Seeds and options are only used once\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_seeds()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:108\u001b[0m, in \u001b[0;36mDummyVecEnv._save_obs\u001b[1;34m(self, env_idx, obs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys:\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 108\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuf_obs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m obs\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_obs[key][env_idx] \u001b[38;5;241m=\u001b[39m obs[key]\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (9,) into shape (3,)"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "# Test the model\n",
    "state = env.reset()\n",
    "for _ in range(10):\n",
    "    action, _states = model.predict(state)\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    print(\"Action:\", action)\n",
    "    print(\"Next State:\", next_state)\n",
    "    print(\"Reward:\", reward)\n",
    "    if done:\n",
    "        state = env.reset()\n",
    "    else:\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b3c9f3-3a46-49bc-95e1-2bd8cc104b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
